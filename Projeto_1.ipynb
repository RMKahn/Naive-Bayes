{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Rafael Meyer Kahn<br>\n",
    "Nome: Hélio Zaia Franciscon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tweepy\n",
    "import math\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle\n",
    "import emoji_list\n",
    "import emoji\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "C:\\Users\\lobda\\Desktop\\Insper\\2º Semestre\\Ciência dos Dados\\DP\\Projeto-1\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e não relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_excel('Netflix.xlsx')\n",
    "teste = pd.read_excel('Netflix.xlsx', 'Teste')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça aqui uma descrição do seu produto e o que considerou como relevante ou não relevante na classificação dos tweets.\n",
    "\n",
    "O produto abordado durante este projeto foi Netflix. Por ser uma provedora global de filmes e séries, existem diversos tweets sobre seu conteúdo, portanto foi levado em consideração 4 níveis de classificação: Irrelevante, Elogio, Crítica e Sugestão. Com isso, pode-se classificar os tweets obtidos nessas 4 categorias para melhor organizar o tipo de comentário que estão fazendo sobre o produto na internet, resultando assim numa melhor distribuição dos tweets para cada área da empresa analisar os fatores relevantes que estão sendo tweetados on-line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Classificacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>achei uma série de investigação policial, agor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uma sequência do clássico está programada para...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#alteredcarbon animação da netflix ganha trail...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sofá, breja e netflix \\nsó na cama vários hits</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>o surto que confundi e corri na netflix achand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>troco em dobro (2020) | nada mais do que puro ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>netflix não conte comigo para mais nada eu me ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rt @hgirardi98: netflix favor parar de lançar ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rt @solteirasince: meu hobby é ficar duas hora...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nao são nem 9h da manhã e já to querendo ir pr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Classificacao\n",
       "0  achei uma série de investigação policial, agor...              1\n",
       "1  uma sequência do clássico está programada para...              0\n",
       "2  #alteredcarbon animação da netflix ganha trail...              0\n",
       "3     sofá, breja e netflix \\nsó na cama vários hits              1\n",
       "4  o surto que confundi e corri na netflix achand...              0\n",
       "5  troco em dobro (2020) | nada mais do que puro ...              0\n",
       "6  netflix não conte comigo para mais nada eu me ...              0\n",
       "7  rt @hgirardi98: netflix favor parar de lançar ...              2\n",
       "8  rt @solteirasince: meu hobby é ficar duas hora...              0\n",
       "9  nao são nem 9h da manhã e já to querendo ir pr...              0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exibindo tweets\n",
    "dados.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo uma função que limpa caractéres indesejados\n",
    "def clean(tabela, titulo):\n",
    "    a = tabela[titulo]\n",
    "    a = a.str.lower()\n",
    "\n",
    "    itens = ['.', ':', ';', '\"', \"'\", '?', '(', ')', '[',']',',', '\\n', '\\t','*','|','+']\n",
    "    i2 = ['?', '!']\n",
    "    emojis = emoji_list.all_emoji\n",
    "    #separa emojis de palavras\n",
    "    for emoji in emojis:\n",
    "        try:\n",
    "            a = a.str.replace(emoji,\" {} \".format(emoji) )\n",
    "        except:\n",
    "            pass\n",
    "    #retira caracteres indesejados\n",
    "    for e in itens:\n",
    "        a = a.str.replace(e,'')\n",
    "    #separa '?' e '!' de palavras\n",
    "    for e in i2:\n",
    "        a = a.str.replace(e,' {} '.format(e))\n",
    "\n",
    "    #Substitui caracteres com acento ou variação por caracteres desejados\n",
    "    a = a.str.replace('é','e')\n",
    "    a = a.str.replace('ê','e')\n",
    "    a = a.str.replace('á','a')\n",
    "    a = a.str.replace('ã','a')\n",
    "    a = a.str.replace('ô','o')\n",
    "    a = a.str.replace('ó','o')\n",
    "    a = a.str.replace('ú','u')\n",
    "    a = a.str.replace('ç','c')\n",
    "    a = a.str.replace('í','i')\n",
    "    a = a.str.replace('@',' @')\n",
    "        \n",
    "    tabela[titulo] = a\n",
    "\n",
    "    return tabela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Classificacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>achei uma serie de investigacao policial agora...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uma sequencia do classico esta programada para...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td># alteredcarbon animacao da netflix ganha tra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sofa breja e netflix so na cama varios hits</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>o surto que confundi e corri na netflix achand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>troco em dobro  2  0  2  0   nada mais do que ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>netflix nao conte comigo para mais nada eu me ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rt  @hgirardi 9  8  netflix favor parar de lan...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rt  @solteirasince meu hobby e ficar duas hora...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nao sao nem  9 h da manha e ja to querendo ir ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Classificacao\n",
       "0  achei uma serie de investigacao policial agora...              1\n",
       "1  uma sequencia do classico esta programada para...              0\n",
       "2   # alteredcarbon animacao da netflix ganha tra...              0\n",
       "3        sofa breja e netflix so na cama varios hits              1\n",
       "4  o surto que confundi e corri na netflix achand...              0\n",
       "5  troco em dobro  2  0  2  0   nada mais do que ...              0\n",
       "6  netflix nao conte comigo para mais nada eu me ...              0\n",
       "7  rt  @hgirardi 9  8  netflix favor parar de lan...              2\n",
       "8  rt  @solteirasince meu hobby e ficar duas hora...              0\n",
       "9  nao sao nem  9 h da manha e ja to querendo ir ...              0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Limpando os dados\n",
    "filtro = clean(dados, 'Treinamento')\n",
    "#Testando\n",
    "filtro.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separando em tabelas por classificação\n",
    "irrelevante = filtro.loc[(filtro.Classificacao == 0)]\n",
    "elogio = filtro.loc[(filtro.Classificacao == 1)]\n",
    "critica = filtro.loc[(filtro.Classificacao == 2)]\n",
    "sugestao = filtro.loc[(filtro.Classificacao == 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo uma função que separa as palavras\n",
    "def tt_split(tabela, titulo):\n",
    "    a = tabela[titulo].str.split(' ')\n",
    "\n",
    "    li = pd.DataFrame()\n",
    "    li['palavras'] = []\n",
    "\n",
    "    for lista in a:\n",
    "        for e in ['#','' , ' ']:\n",
    "            while lista.count(e) != 0:\n",
    "                lista.remove(e)\n",
    "\n",
    "        for palavra in lista:\n",
    "            if '@' in palavra and palavra != '@':\n",
    "                lista.remove(palavra) \n",
    "            if palavra[:4] == 'http':\n",
    "                lista.remove(palavra)\n",
    "        li = li.append({'palavras': lista}, ignore_index=True)\n",
    "                \n",
    "    return li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavras</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[achei, uma, serie, de, investigacao, policial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[sofa, breja, e, netflix, so, na, cama, varios...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[estou, assistindo, uma, serie, mt, boa, sobre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[rt, a, historia, do, lil, peep, e, incrivel, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[acabei, de, assistir, a, animacao, de, pokemo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[rt, melhor, date, do, mundo, e, em, casa, dei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[almocar, a, ver, um, filme, random, da, netfl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[meu, deus, agora, que, eu, vi, que, tem, itae...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[e, a, netflix, que, vai, lancar, uma, serie, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[a, netflix, ate, que, tem, um, acervo, bom, d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            palavras\n",
       "0  [achei, uma, serie, de, investigacao, policial...\n",
       "1  [sofa, breja, e, netflix, so, na, cama, varios...\n",
       "2  [estou, assistindo, uma, serie, mt, boa, sobre...\n",
       "3  [rt, a, historia, do, lil, peep, e, incrivel, ...\n",
       "4  [acabei, de, assistir, a, animacao, de, pokemo...\n",
       "5  [rt, melhor, date, do, mundo, e, em, casa, dei...\n",
       "6  [almocar, a, ver, um, filme, random, da, netfl...\n",
       "7  [meu, deus, agora, que, eu, vi, que, tem, itae...\n",
       "8  [e, a, netflix, que, vai, lancar, uma, serie, ...\n",
       "9  [a, netflix, ate, que, tem, um, acervo, bom, d..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Separando os tweets das tabelas limpas\n",
    "irrelevante_limpa = tt_split(irrelevante, 'Treinamento')\n",
    "elogio_limpa = tt_split(elogio, 'Treinamento')\n",
    "critica_limpa = tt_split(critica, 'Treinamento')\n",
    "sugestao_limpa = tt_split(sugestao, 'Treinamento')\n",
    "todos_limpa = tt_split(filtro, 'Treinamento')\n",
    "#Testando\n",
    "elogio_limpa.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo função que cria tabela com as palavras separadas\n",
    "def palavras(tabela):\n",
    "    a = tabela['palavras']\n",
    "    prob = pd.DataFrame()\n",
    "    prob['palavras'] = []\n",
    "    for lista in a:\n",
    "        for e in lista:\n",
    "            prob = prob.append({'palavras': e}, ignore_index=True)\n",
    "    \n",
    "    return prob['palavras']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           achei\n",
       "1             uma\n",
       "2           serie\n",
       "3              de\n",
       "4    investigacao\n",
       "5        policial\n",
       "6           agora\n",
       "7              eu\n",
       "8           nunca\n",
       "9            mais\n",
       "Name: palavras, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Separando as palavras\n",
    "irrelevante_separada = palavras(irrelevante_limpa)\n",
    "elogio_separada = palavras(elogio_limpa)\n",
    "critica_separada = palavras(critica_limpa)\n",
    "sugestao_separada = palavras(sugestao_limpa)\n",
    "todos_separada = palavras(todos_limpa)\n",
    "#Testando\n",
    "elogio_separada.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "netflix    111\n",
       "e           78\n",
       "a           58\n",
       "de          52\n",
       "que         50\n",
       "na          46\n",
       "eu          36\n",
       "um          28\n",
       "o           28\n",
       "serie       25\n",
       "Name: palavras, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obtendo as frequências absolutas\n",
    "freq_irrelevante = irrelevante_separada.value_counts()\n",
    "freq_elogio = elogio_separada.value_counts()\n",
    "freq_critica = critica_separada.value_counts()\n",
    "freq_sugestao = sugestao_separada.value_counts()\n",
    "freq_todos = todos_separada.value_counts()\n",
    "#Testando\n",
    "freq_elogio.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "netflix    0.055005\n",
       "e          0.038652\n",
       "a          0.028741\n",
       "de         0.025768\n",
       "que        0.024777\n",
       "na         0.022795\n",
       "eu         0.017839\n",
       "um         0.013875\n",
       "o          0.013875\n",
       "serie      0.012389\n",
       "Name: palavras, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obtendo as frequências relativas\n",
    "freq_rel_irrelevante = irrelevante_separada.value_counts(True)\n",
    "freq_rel_elogio = elogio_separada.value_counts(True)\n",
    "freq_rel_critica = critica_separada.value_counts(True)\n",
    "freq_rel_sugestao = sugestao_separada.value_counts(True)\n",
    "freq_rel_todos = todos_separada.value_counts(True)\n",
    "#Testando\n",
    "freq_rel_elogio.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste['Bot'] = 0\n",
    "teste['Resultado'] = pd.Series()\n",
    "teste_clean = clean(teste,'Teste')\n",
    "teste_f = tt_split(teste_clean,'Teste')\n",
    "\n",
    "#função para multiplicar itens dentro de uma lista\n",
    "def multiplica(Lista) :     \n",
    "    u = 1\n",
    "    for x in Lista: \n",
    "         u = u * x  \n",
    "    return u  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavras</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[to, sem, netflix, que, triste, como, q, vou, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[e, vamos, de, netflix, maior, e, melhor]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[@kelcyrus, ja, pode, fechar, contrato, com, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[sim, tiraram, o, meu, dorama, favorito, da, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[rt, netflix, lanca, sua, primeira, serie, sul...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            palavras\n",
       "0  [to, sem, netflix, que, triste, como, q, vou, ...\n",
       "1          [e, vamos, de, netflix, maior, e, melhor]\n",
       "2  [@kelcyrus, ja, pode, fechar, contrato, com, a...\n",
       "3  [sim, tiraram, o, meu, dorama, favorito, da, n...\n",
       "4  [rt, netflix, lanca, sua, primeira, serie, sul..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste_f.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lobda\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\lobda\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\lobda\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "C:\\Users\\lobda\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\lobda\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\lobda\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\lobda\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\lobda\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\lobda\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\lobda\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\lobda\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\lobda\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\lobda\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for lin in teste_f['palavras']:\n",
    "    p0 = 1\n",
    "    p1 = 1\n",
    "    p2 = 1\n",
    "    p3 = 1\n",
    "    sim = 1\n",
    "    nao = 0\n",
    "    prob1 = []\n",
    "    prob0 = []\n",
    "    prob2 = []\n",
    "    prob3 = []\n",
    "    for palavra in lin:\n",
    "        try:\n",
    "            p0 *= (freq_irrelevante[palavra] +1)/(sum(freq_irrelevante) + len(freq_todos))\n",
    "            prob0.append(p0)\n",
    "        except:\n",
    "            p0 *= 1/(sum(freq_irrelevante) + len(freq_todos))\n",
    "            prob0.append(p0)\n",
    "        try:\n",
    "            p1 *= (freq_elogio[palavra] +1)/(sum(freq_elogio) + len(freq_todos))\n",
    "            prob1.append(p1)\n",
    "        except:\n",
    "            p1 *= 1/(sum(freq_elogio) + len(freq_todos))\n",
    "            prob1.append(p1)\n",
    "        try:\n",
    "            p2 *= (freq_critica[palavra] +1)/(sum(freq_critica) + len(freq_todos))\n",
    "            prob2.append(p2)\n",
    "        except:\n",
    "            p2 *= 1/(sum(freq_critica) + len(freq_todos))\n",
    "            prob2.append(p2)\n",
    "        try:\n",
    "            p3 *= (freq_sugestao[palavra] +1)/(sum(freq_sugestao) + len(freq_todos))\n",
    "            prob3.append(p3)\n",
    "        except:\n",
    "            p3 *= 1/(sum(freq_sugestao) + len(freq_todos))\n",
    "            prob3.append(p3)\n",
    "            \n",
    "    multiplica0 = multiplica(prob0)*(sum(freq_irrelevante)/sum(freq_todos))   \n",
    "    multiplica1 = multiplica(prob1)*(sum(freq_elogio)/sum(freq_todos))\n",
    "    multiplica2 = multiplica(prob2)*(sum(freq_critica)/sum(freq_todos))   \n",
    "    multiplica3 = multiplica(prob3)*(sum(freq_sugestao)/sum(freq_todos))\n",
    "    \n",
    "    \n",
    "    \n",
    "    if (multiplica0>multiplica1) & (multiplica0 > multiplica2) & (multiplica0 > multiplica3):\n",
    "        teste['Bot'][i] = 0\n",
    "        if teste['Bot'][i] == teste['Classificacao'][i]:\n",
    "            teste['Resultado'][i] = 'Positivo Verdadeiro'\n",
    "        elif teste['Bot'][i] != teste['Classificacao'][i]:\n",
    "            teste['Resultado'][i] = 'Positivo Falso'\n",
    "    elif (multiplica1>multiplica0) & (multiplica1 > multiplica2) & (multiplica1 > multiplica3):\n",
    "        teste['Bot'][i] = 1\n",
    "        if teste['Bot'][i] == teste['Classificacao'][i]:\n",
    "            teste['Resultado'][i] = 'Negativo Verdadeiro'\n",
    "        elif teste['Bot'][i] != teste['Classificacao'][i]:\n",
    "            teste['Resultado'][i] = 'Negativo Falso'\n",
    "    elif (multiplica2>multiplica0) & (multiplica2 > multiplica1) & (multiplica2 > multiplica3):\n",
    "        teste['Bot'][i] = 2\n",
    "        if teste['Bot'][i] == teste['Classificacao'][i]:\n",
    "            teste['Resultado'][i] = 'Negativo Verdadeiro'\n",
    "        elif teste['Bot'][i] != teste['Classificacao'][i]:\n",
    "            teste['Resultado'][i] = 'Negativo Falso'\n",
    "    else:\n",
    "        teste['Bot'][i] = 3\n",
    "        if teste['Bot'][i] == teste['Classificacao'][i]:\n",
    "            teste['Resultado'][i] = 'Negativo Verdadeiro'\n",
    "        elif teste['Bot'][i] != teste['Classificacao'][i]:\n",
    "            teste['Resultado'][i] = 'Negativo Falso'\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Bot</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classificacao</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1775</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.0225</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.1025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.1125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Bot                 0       1      2       3\n",
       "Classificacao                               \n",
       "0              0.1775  0.0400  0.040  0.3125\n",
       "1              0.0300  0.0225  0.020  0.1025\n",
       "2              0.0375  0.0150  0.025  0.1125\n",
       "3              0.0125  0.0050  0.005  0.0425"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = pd.crosstab(teste['Classificacao'], teste['Bot'], normalize = True)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Criando função para plotar o gráfico\n",
    "def plot_confusion_matrix(df_confusion, cmap=plt.cm.Blues):\n",
    "    plt.matshow(df_confusion, cmap=cmap) # imshow\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(df_confusion.columns))\n",
    "    plt.xticks(tick_marks, df_confusion.columns, rotation=45)\n",
    "    plt.yticks(tick_marks, df_confusion.index)\n",
    "\n",
    "#Plotando o gráfico    \n",
    "plot_confusion_matrix(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O calssificador apresentou baixa precisão ao classificar os tweets devido à sua base de treino, esse fato deve-se à forma como os tweets sobre o título escolhido, Netflix, são compostos.\n",
    "\n",
    "Grande parte dos tweets em nosso DataFrame possuem mais de uma forma de serem classificados, e muitas vezes não se adequam perfeitamente às classificações propostas, dessa forma ao treinar o algorítimo para aprender a classifica-los ocorre uma alteração em como o classificador contabiliza as frases devido as palavras presentes nesses tweets que acabam sendo levados em conta na hora de classificar um tweet qualquer, ou seja, no momento em que nosso algoritimo classifica um tweet ele leva em conta o numero total de palavras e a chance de ocorrencia de cada uma delas em uma frase, assim levando em conta também as palavras presentes nesses tweets ambiguos, o que favorece uma classificação menos precisa do tweet sendo analisado.\n",
    "\n",
    "Como a base de tweets a ser classificado é grande, assim como o numero de tweets ambiguos, acaba ocorrendo uma série de classificações erradas, o que acaba por deixar o algoritimo pouco preciso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proposta de melhora\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tendo em vista os motivos pelos quais o nosso algoritimo apresentou uma precisão abaixo da desejada: problemas com tweets ambiguos e de duvidosa classificação. Uma forma de melhorar a precisão seria: Revisar o DataFrame \"Treinamento\" com o qual nosso classificador \"Aprende\" a classificar os tweets, de modo a deixa-lo o mais limpo de tweets ambiguos quanto possível. \n",
    "\n",
    "Para fazer isso teriamos que revisar o DataFrame \"Treinamento\" em busca dos tweets em que houveram dificuldades de classificação, e substitui-los por tweets mais coerentes que não deixassem qualquer duvida sobre como proderiam ser classificados, ou seja, uma classificação absoluta. Dessa forma ao contabilizar as palavras presentes nesse novos tweets (e ao mesmo tempo deixando de levar em conta as palavras presentes nos tweets ambiguos) teriamos uma classificação mais precisa, pois as palavras estariam com suas probabilidades de ocorrencia em um tweet qualquer sobre o titulo escolhido (Netflix) mais exatas, resultando em um algoritimo que melhor classificaria os tweets do DataFrame \"Teste\"\n",
    "\n",
    "Além disso, outra melhoria importante no classificador seria obter uma base de dados classificada de forma mais homogênea, ou seja, obter uma base de treinamento com algo entorno de 25% dos tweets classificados para cada categoria, já que isso faria com que as probabilidades de cada categoria fossem mais corretas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usos fora do contexto do projeto\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Além de classificação de sentimentos, como abordado durante este projeto, o método de Naïve Bayes pode ser usados em diversos outros contextos, como por exemplo o sistema de filtragem de e-mails. Ele pode ser usado para classificar um e-mail como SPAM ou lixo eletrônico para assim deixar a caixa de e-mail dos usuários mais limpas e sem itens indesejados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**\n",
    "\n",
    "https://www.datageeks.com.br/naive-bayes/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
