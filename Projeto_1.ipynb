{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Rafael Meyer Kahn<br>\n",
    "Nome: Hélio Zaia Franciscon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'emoji'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-a54478aefc9f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mrandom\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0memoji_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0memoji\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexport_graphviz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'emoji'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tweepy\n",
    "import math\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle\n",
    "import emoji_list\n",
    "import emoji\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e não relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_excel('Netflix.xlsx')\n",
    "teste = pd.read_excel('Netflix.xlsx', 'Teste')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça aqui uma descrição do seu produto e o que considerou como relevante ou não relevante na classificação dos tweets.\n",
    "\n",
    "O produto abordado durante este projeto foi Netflix. Por ser uma provedora global de filmes e séries, existem diversos tweets sobre seu conteúdo, portanto foi levado em consideração 4 níveis de classificação: Irrelevante, Elogio, Crítica e Sugestão. Com isso, pode-se classificar os tweets obtidos nessas 4 categorias para melhor organizar o tipo de comentário que estão fazendo sobre o produto na internet, resultando assim numa melhor distribuição dos tweets para cada área da empresa analisar os fatores relevantes que estão sendo tweetados on-line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exibindo tweets\n",
    "dados.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo uma função que limpa caractéres indesejados\n",
    "def clean(tabela, titulo):\n",
    "    a = tabela[titulo]\n",
    "    a = a.str.lower()\n",
    "\n",
    "    itens = ['.', ':', ';', '\"', \"'\", '?', '(', ')', '[',']',',', '\\n', '\\t','*','|','+']\n",
    "    i2 = ['?', '!']\n",
    "    emojis = emoji_list.all_emoji\n",
    "    #separa emojis de palavras\n",
    "    for emoji in emojis:\n",
    "        try:\n",
    "            a = a.str.replace(emoji,\" {} \".format(emoji) )\n",
    "        except:\n",
    "            pass\n",
    "    #retira caracteres indesejados\n",
    "    for e in itens:\n",
    "        a = a.str.replace(e,'')\n",
    "    #separa '?' e '!' de palavras\n",
    "    for e in i2:\n",
    "        a = a.str.replace(e,' {} '.format(e))\n",
    "\n",
    "    #Substitui caracteres com acento ou variação por caracteres desejados\n",
    "    a = a.str.replace('é','e')\n",
    "    a = a.str.replace('ê','e')\n",
    "    a = a.str.replace('á','a')\n",
    "    a = a.str.replace('ã','a')\n",
    "    a = a.str.replace('ô','o')\n",
    "    a = a.str.replace('ó','o')\n",
    "    a = a.str.replace('ú','u')\n",
    "    a = a.str.replace('ç','c')\n",
    "    a = a.str.replace('í','i')\n",
    "    a = a.str.replace('@',' @')\n",
    "        \n",
    "    tabela[titulo] = a\n",
    "\n",
    "    return tabela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpando os dados\n",
    "filtro = clean(dados, 'Treinamento')\n",
    "#Testando\n",
    "filtro.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separando em tabelas por classificação\n",
    "irrelevante = filtro.loc[(filtro.Classificacao == 0)]\n",
    "elogio = filtro.loc[(filtro.Classificacao == 1)]\n",
    "critica = filtro.loc[(filtro.Classificacao == 2)]\n",
    "sugestao = filtro.loc[(filtro.Classificacao == 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo uma função que separa as palavras\n",
    "def tt_split(tabela, titulo):\n",
    "    a = tabela[titulo].str.split(' ')\n",
    "\n",
    "    li = pd.DataFrame()\n",
    "    li['palavras'] = []\n",
    "\n",
    "    for lista in a:\n",
    "        for e in ['#','' , ' ']:\n",
    "            while lista.count(e) != 0:\n",
    "                lista.remove(e)\n",
    "\n",
    "        for palavra in lista:\n",
    "            if '@' in palavra and palavra != '@':\n",
    "                lista.remove(palavra) \n",
    "            if palavra[:4] == 'http':\n",
    "                lista.remove(palavra)\n",
    "        li = li.append({'palavras': lista}, ignore_index=True)\n",
    "                \n",
    "    return li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separando os tweets das tabelas limpas\n",
    "irrelevante_limpa = tt_split(irrelevante, 'Treinamento')\n",
    "elogio_limpa = tt_split(elogio, 'Treinamento')\n",
    "critica_limpa = tt_split(critica, 'Treinamento')\n",
    "sugestao_limpa = tt_split(sugestao, 'Treinamento')\n",
    "todos_limpa = tt_split(filtro, 'Treinamento')\n",
    "#Testando\n",
    "elogio_limpa.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo função que cria tabela com as palavras separadas\n",
    "def palavras(tabela):\n",
    "    a = tabela['palavras']\n",
    "    prob = pd.DataFrame()\n",
    "    prob['palavras'] = []\n",
    "    for lista in a:\n",
    "        for e in lista:\n",
    "            prob = prob.append({'palavras': e}, ignore_index=True)\n",
    "    \n",
    "    return prob['palavras']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separando as palavras\n",
    "irrelevante_separada = palavras(irrelevante_limpa)\n",
    "elogio_separada = palavras(elogio_limpa)\n",
    "critica_separada = palavras(critica_limpa)\n",
    "sugestao_separada = palavras(sugestao_limpa)\n",
    "todos_separada = palavras(todos_limpa)\n",
    "#Testando\n",
    "elogio_separada.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtendo as frequências absolutas\n",
    "freq_irrelevante = irrelevante_separada.value_counts()\n",
    "freq_elogio = elogio_separada.value_counts()\n",
    "freq_critica = critica_separada.value_counts()\n",
    "freq_sugestao = sugestao_separada.value_counts()\n",
    "freq_todos = todos_separada.value_counts()\n",
    "#Testando\n",
    "freq_elogio.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtendo as frequências relativas\n",
    "freq_rel_irrelevante = irrelevante_separada.value_counts(True)\n",
    "freq_rel_elogio = elogio_separada.value_counts(True)\n",
    "freq_rel_critica = critica_separada.value_counts(True)\n",
    "freq_rel_sugestao = sugestao_separada.value_counts(True)\n",
    "freq_rel_todos = todos_separada.value_counts(True)\n",
    "#Testando\n",
    "freq_rel_elogio.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'teste' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-1e41296d70ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mteste\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Bot'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mteste\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Resultado'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mteste_clean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mteste\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Teste'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mteste_f\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtt_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mteste_clean\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Teste'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'teste' is not defined"
     ]
    }
   ],
   "source": [
    "teste['Bot'] = 0\n",
    "teste['Resultado'] = pd.Series()\n",
    "teste_clean = clean(teste,'Teste')\n",
    "teste_f = tt_split(teste_clean,'Teste')\n",
    "\n",
    "#função para multiplicar itens dentro de uma lista\n",
    "def multiplica(Lista) :     \n",
    "    u = 1\n",
    "    for x in Lista: \n",
    "         u = u * x  \n",
    "    return u  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste_f.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for lin in teste_f['palavras']:\n",
    "    p0 = 1\n",
    "    p1 = 1\n",
    "    p2 = 1\n",
    "    p3 = 1\n",
    "    sim = 1\n",
    "    nao = 0\n",
    "    prob1 = []\n",
    "    prob0 = []\n",
    "    prob2 = []\n",
    "    prob3 = []\n",
    "    for palavra in lin:\n",
    "        try:\n",
    "            p0 *= (freq_irrelevante[palavra] +1)/(sum(freq_irrelevante) + len(freq_todos))\n",
    "            prob0.append(p0)\n",
    "        except:\n",
    "            p0 *= 1/(sum(freq_irrelevante) + len(freq_todos))\n",
    "            prob0.append(p0)\n",
    "        try:\n",
    "            p1 *= (freq_elogio[palavra] +1)/(sum(freq_elogio) + len(freq_todos))\n",
    "            prob1.append(p1)\n",
    "        except:\n",
    "            p1 *= 1/(sum(freq_elogio) + len(freq_todos))\n",
    "            prob1.append(p1)\n",
    "        try:\n",
    "            p2 *= (freq_critica[palavra] +1)/(sum(freq_critica) + len(freq_todos))\n",
    "            prob2.append(p2)\n",
    "        except:\n",
    "            p2 *= 1/(sum(freq_critica) + len(freq_todos))\n",
    "            prob2.append(p2)\n",
    "        try:\n",
    "            p3 *= (freq_sugestao[palavra] +1)/(sum(freq_sugestao) + len(freq_todos))\n",
    "            prob3.append(p3)\n",
    "        except:\n",
    "            p3 *= 1/(sum(freq_sugestao) + len(freq_todos))\n",
    "            prob3.append(p3)\n",
    "            \n",
    "    multiplica0 = multiplica(prob0)*(sum(freq_irrelevante)/sum(freq_todos))   \n",
    "    multiplica1 = multiplica(prob1)*(sum(freq_elogio)/sum(freq_todos))\n",
    "    multiplica2 = multiplica(prob2)*(sum(freq_critica)/sum(freq_todos))   \n",
    "    multiplica3 = multiplica(prob3)*(sum(freq_sugestao)/sum(freq_todos))\n",
    "    \n",
    "    \n",
    "    \n",
    "    if (multiplica0>multiplica1) & (multiplica0 > multiplica2) & (multiplica0 > multiplica3):\n",
    "        teste['Bot'][i] = 0\n",
    "        if teste['Bot'][i] == teste['Classificacao'][i]:\n",
    "            teste['Resultado'][i] = 'Positivo Verdadeiro'\n",
    "        elif teste['Bot'][i] != teste['Classificacao'][i]:\n",
    "            teste['Resultado'][i] = 'Positivo Falso'\n",
    "    elif (multiplica1>multiplica0) & (multiplica1 > multiplica2) & (multiplica1 > multiplica3):\n",
    "        teste['Bot'][i] = 1\n",
    "        if teste['Bot'][i] == teste['Classificacao'][i]:\n",
    "            teste['Resultado'][i] = 'Negativo Verdadeiro'\n",
    "        elif teste['Bot'][i] != teste['Classificacao'][i]:\n",
    "            teste['Resultado'][i] = 'Negativo Falso'\n",
    "    elif (multiplica2>multiplica0) & (multiplica2 > multiplica1) & (multiplica2 > multiplica3):\n",
    "        teste['Bot'][i] = 2\n",
    "        if teste['Bot'][i] == teste['Classificacao'][i]:\n",
    "            teste['Resultado'][i] = 'Negativo Verdadeiro'\n",
    "        elif teste['Bot'][i] != teste['Classificacao'][i]:\n",
    "            teste['Resultado'][i] = 'Negativo Falso'\n",
    "    else:\n",
    "        teste['Bot'][i] = 3\n",
    "        if teste['Bot'][i] == teste['Classificacao'][i]:\n",
    "            teste['Resultado'][i] = 'Negativo Verdadeiro'\n",
    "        elif teste['Bot'][i] != teste['Classificacao'][i]:\n",
    "            teste['Resultado'][i] = 'Negativo Falso'\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = pd.crosstab(teste['Classificacao'], teste['Bot'], normalize = True)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando função para plotar o gráfico\n",
    "def plot_confusion_matrix(df_confusion, cmap=plt.cm.Blues):\n",
    "    plt.matshow(df_confusion, cmap=cmap) # imshow\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(df_confusion.columns))\n",
    "    plt.xticks(tick_marks, df_confusion.columns, rotation=45)\n",
    "    plt.yticks(tick_marks, df_confusion.index)\n",
    "\n",
    "#Plotando o gráfico    \n",
    "plot_confusion_matrix(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('% classificados como 0',(sum(freq_irrelevante)/sum(freq_todos)))\n",
    "print('% classificados como 1',(sum(freq_elogio)/sum(freq_todos)))\n",
    "print('% classificados como 2',(sum(freq_critica)/sum(freq_todos)))\n",
    "print('% classificados como 3',(sum(freq_sugestao)/sum(freq_todos)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O calssificador apresentou baixa precisão ao classificar os tweets devido à sua base de treino, esse fato deve-se à forma como os tweets sobre o título escolhido, Netflix, são compostos.\n",
    "\n",
    "Grande parte dos tweets em nosso DataFrame possuem mais de uma forma de serem classificados, e muitas vezes não se adequam perfeitamente às classificações propostas, dessa forma ao treinar o algorítimo para aprender a classifica-los ocorre uma alteração em como o classificador contabiliza as frases devido as palavras presentes nesses tweets que acabam sendo levados em conta na hora de classificar um tweet qualquer, ou seja, no momento em que nosso algoritimo classifica um tweet ele leva em conta o numero total de palavras e a chance de ocorrencia de cada uma delas em uma frase, assim levando em conta também as palavras presentes nesses tweets ambiguos, o que favorece uma classificação menos precisa do tweet sendo analisado.\n",
    "\n",
    "Como a base de tweets a ser classificado é grande, assim como o numero de tweets ambiguos, acaba ocorrendo uma série de classificações erradas, o que acaba por deixar o algoritimo pouco preciso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proposta de melhora\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tendo em vista os motivos pelos quais o nosso algoritimo apresentou uma precisão abaixo da desejada: problemas com tweets ambiguos e de duvidosa classificação. Uma forma de melhorar a precisão seria: Revisar o DataFrame \"Treinamento\" com o qual nosso classificador \"Aprende\" a classificar os tweets, de modo a deixa-lo o mais limpo de tweets ambiguos quanto possível. \n",
    "\n",
    "Para fazer isso teriamos que revisar o DataFrame \"Treinamento\" em busca dos tweets em que houveram dificuldades de classificação, e substitui-los por tweets mais coerentes que não deixassem qualquer duvida sobre como proderiam ser classificados, ou seja, uma classificação absoluta. Dessa forma ao contabilizar as palavras presentes nesse novos tweets (e ao mesmo tempo deixando de levar em conta as palavras presentes nos tweets ambiguos) teriamos uma classificação mais precisa, pois as palavras estariam com suas probabilidades de ocorrencia em um tweet qualquer sobre o titulo escolhido (Netflix) mais exatas, resultando em um algoritimo que melhor classificaria os tweets do DataFrame \"Teste\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
